{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "dependencies",
   "id": "d42e7ffd121acab6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# for google colab\n",
    "# !pip install torchsparsegradutils torch_geometric"
   ],
   "id": "e2f01c61753b5483"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchsparsegradutils\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.utils import structured_negative_sampling"
   ],
   "id": "77904966c7868dea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "_alpha = 0.8\n",
    "_hidden_dim = 64\n",
    "_sample_hop = 6\n",
    "_eigs_dim = 64\n",
    "_model = \"eig+path\"\n",
    "_n_layers = 3\n",
    "_learning_rate = 1e-2\n",
    "_topks = [5, 10, 15, 20]\n",
    "_test_batch_size = 1024\n",
    "_lambda_reg = 1e-4\n",
    "_beta = 0.2\n",
    "_offset = 1\n",
    "_show_loss_interval = 1\n",
    "_epochs = 1000\n",
    "_valid_interval = 20\n",
    "_stopping_step = 10\n",
    "_train_file = \"data/train.txt\"\n",
    "_valid_file = \"data/valid.txt\"\n",
    "_test_file = \"data/test.txt\""
   ],
   "id": "f79363091dce4c94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "utility functions",
   "id": "ddefede398d3ab39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def getlabel(test_data, pred_data):\n",
    "    r, recall_n = [], []\n",
    "    for i in range(len(pred_data)):\n",
    "        groundTrue = test_data[i]\n",
    "        predictTopK = pred_data[i]\n",
    "        if len(groundTrue) > 0:\n",
    "            r.append(list(map(lambda x: x in groundTrue, predictTopK)))\n",
    "            recall_n.append(len(groundTrue))\n",
    "    return np.array(r), recall_n\n",
    "\n",
    "\n",
    "def test(sorted_items, groundTrue):\n",
    "    sorted_items = sorted_items.cpu().numpy()\n",
    "    r, recall_n = getlabel(groundTrue, sorted_items)\n",
    "    pre, recall, ndcg, ndcg2 = [], [], [], []\n",
    "    for k in _topks:\n",
    "        now_k = min(k, r.shape[1])\n",
    "        pred = r[:, :now_k]\n",
    "        right_pred = pred.sum(1)\n",
    "        # precision\n",
    "        pre.append(np.sum(right_pred / now_k))\n",
    "        # recall\n",
    "        recall.append(np.sum(right_pred / recall_n))\n",
    "        # ndcg\n",
    "        dcg = np.sum(pred * (1. / np.log2(np.arange(2, now_k + 2))), axis=1)\n",
    "        d_val = [np.sum(1. / np.log2(np.arange(2, i + 2)))\n",
    "                 for i in range(0, now_k + 1)]\n",
    "        idcg = np.array([d_val[int(i)] for i in np.minimum(recall_n, now_k)])\n",
    "        ndcg.append(np.sum(dcg / idcg))\n",
    "    return torch.tensor(pre), torch.tensor(recall), torch.tensor(ndcg)\n",
    "\n",
    "\n",
    "def sum_norm(indices, values, n):\n",
    "    s = torch.zeros(n, device=values.device).scatter_add(0, indices[0], values)\n",
    "    s[s == 0.] = 1.\n",
    "    return values / s[indices[0]]\n",
    "\n",
    "\n",
    "def sparse_softmax(indices, values, n):\n",
    "    return sum_norm(indices, torch.clamp(torch.exp(values), min=-5, max=5), n)"
   ],
   "id": "65eab7f209f287d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "model",
   "id": "bf1aa0a6ead8e913"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.lambda0 = nn.Parameter(torch.zeros(1))\n",
    "        self.path_emb = nn.Embedding(2 ** (_sample_hop + 1) - 2, 1)\n",
    "        nn.init.zeros_(self.path_emb.weight)\n",
    "        self.sqrt_dim = 1.0 / torch.sqrt(torch.tensor(_hidden_dim))\n",
    "        self.sqrt_eig = 1.0 / torch.sqrt(torch.tensor(_eigs_dim))\n",
    "        self.my_parameters = [\n",
    "            {\"params\": self.lambda0, \"weight_decay\": 1e-2},\n",
    "            {\"params\": self.path_emb.parameters()},\n",
    "        ]\n",
    "\n",
    "    def forward(self, q, k, v, indices, eigs, path_type):\n",
    "        ni, nx, ny, nz = [], [], [], []\n",
    "        for i, pt in zip(indices, path_type):\n",
    "            x = torch.mul(q[i[0]], k[i[1]]).sum(dim=-1) * self.sqrt_dim\n",
    "            nx.append(x)\n",
    "            if \"eig\" in _model:\n",
    "                if _eigs_dim == 0:\n",
    "                    y = torch.zeros(i.shape[1]).to(_device)\n",
    "                else:\n",
    "                    y = torch.mul(eigs[i[0]], eigs[i[1]]).sum(dim=-1)\n",
    "                ny.append(y)\n",
    "            if \"path\" in _model:\n",
    "                z = self.path_emb(pt).view(-1)\n",
    "                nz.append(z)\n",
    "            ni.append(i)\n",
    "        i = torch.concat(ni, dim=-1)\n",
    "        s = []\n",
    "        s.append(torch.concat(nx, dim=-1))\n",
    "        if \"eig\" in _model:\n",
    "            s[0] = s[0] + torch.exp(self.lambda0) * torch.concat(ny, dim=-1)\n",
    "        if \"path\" in _model:\n",
    "            s.append(torch.concat(nz, dim=-1))\n",
    "        s = [sparse_softmax(i, _, q.shape[0]) for _ in s]\n",
    "        s = torch.stack(s, dim=1).mean(dim=1)\n",
    "        return torchsparsegradutils.sparse_mm(\n",
    "            torch.sparse_coo_tensor(i, s, torch.Size([q.shape[0], k.shape[0]])), v\n",
    "        )\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.self_attention = Attention()\n",
    "        self.my_parameters = self.self_attention.my_parameters\n",
    "\n",
    "    def forward(self, x, indices, eigs, path_type):\n",
    "        y = F.layer_norm(x, normalized_shape=(_hidden_dim,))\n",
    "        y = self.self_attention(y, y, y, indices, eigs, path_type)\n",
    "        return y\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Model, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.hidden_dim = _hidden_dim\n",
    "        self.n_layers = _n_layers\n",
    "        self.embedding_user = nn.Embedding(self.dataset.num_users, self.hidden_dim)\n",
    "        self.embedding_item = nn.Embedding(self.dataset.num_items, self.hidden_dim)\n",
    "        nn.init.normal_(self.embedding_user.weight, std=0.1)\n",
    "        nn.init.normal_(self.embedding_item.weight, std=0.1)\n",
    "        self.my_parameters = [\n",
    "            {\"params\": self.embedding_user.parameters()},\n",
    "            {\"params\": self.embedding_item.parameters()},\n",
    "        ]\n",
    "        self.layers = []\n",
    "        for i in range(_n_layers):\n",
    "            layer = Encoder().to(_device)\n",
    "            self.layers.append(layer)\n",
    "            self.my_parameters.extend(layer.my_parameters)\n",
    "        self._users, self._items = None, None\n",
    "        self.optimizer = torch.optim.Adam(self.my_parameters, lr=_learning_rate)\n",
    "\n",
    "    def computer(self):\n",
    "        users_emb = self.embedding_user.weight\n",
    "        items_emb = self.embedding_item.weight\n",
    "        all_emb = torch.cat([users_emb, items_emb])\n",
    "        embs = [all_emb]\n",
    "        for i in range(self.n_layers):\n",
    "            indices, paths = self.dataset.sample()\n",
    "            all_emb = self.layers[i](all_emb, indices, self.dataset.L_eigs, paths)\n",
    "            embs.append(all_emb)\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        light_out = torch.mean(embs, dim=1)\n",
    "        self._users, self._items = torch.split(\n",
    "            light_out, [self.dataset.num_users, self.dataset.num_items]\n",
    "        )\n",
    "\n",
    "    def evaluate(self, test_pos_unique_users, test_pos_list, test_neg_list):\n",
    "        self.eval()\n",
    "        if self._users is None:\n",
    "            self.computer()\n",
    "        user_emb, item_emb = self._users, self._items\n",
    "        max_K = max(_topks)\n",
    "        all_pre = torch.zeros(len(_topks))\n",
    "        all_recall = torch.zeros(len(_topks))\n",
    "        all_ndcg = torch.zeros(len(_topks))\n",
    "        with torch.no_grad():\n",
    "            users = test_pos_unique_users\n",
    "            for i in range(0, users.shape[0], _test_batch_size):\n",
    "                batch_users = users[i: i + _test_batch_size]\n",
    "                user_e = user_emb[batch_users]\n",
    "                rating = torch.mm(user_e, item_emb.t())\n",
    "                for j, u in enumerate(batch_users):\n",
    "                    rating[j, self.dataset.train_pos_list[u]] = -(1 << 10)\n",
    "                    rating[j, self.dataset.train_neg_list[u]] = -(1 << 10)\n",
    "                _, rating = torch.topk(rating, k=max_K)\n",
    "                pre, recall, ndcg = test(\n",
    "                    rating, test_pos_list[i: i + _test_batch_size]\n",
    "                )\n",
    "                all_pre += pre\n",
    "                all_recall += recall\n",
    "                all_ndcg += ndcg\n",
    "            all_pre /= users.shape[0]\n",
    "            all_recall /= users.shape[0]\n",
    "            all_ndcg /= users.shape[0]\n",
    "        return all_pre, all_recall, all_ndcg\n",
    "\n",
    "    def valid_func(self):\n",
    "        return self.evaluate(\n",
    "            self.dataset.valid_pos_unique_users,\n",
    "            self.dataset.valid_pos_list,\n",
    "            self.dataset.valid_neg_list,\n",
    "        )\n",
    "\n",
    "    def test_func(self):\n",
    "        return self.evaluate(\n",
    "            self.dataset.test_pos_unique_users,\n",
    "            self.dataset.test_pos_list,\n",
    "            self.dataset.valid_neg_list,\n",
    "        )\n",
    "\n",
    "    def train_func(self):\n",
    "        self.train()\n",
    "        pos_u = self.dataset.train_pos_user\n",
    "        pos_i = self.dataset.train_pos_item\n",
    "        indices = torch.randperm(self.dataset.train_neg_user.shape[0])\n",
    "        neg_u = self.dataset.train_neg_user[indices]\n",
    "        neg_i = self.dataset.train_neg_item[indices]\n",
    "        all_j = structured_negative_sampling(\n",
    "            torch.concat(\n",
    "                [torch.stack([pos_u, pos_i]), torch.stack([neg_u, neg_i])], dim=1\n",
    "            ),\n",
    "            num_nodes=self.dataset.num_items,\n",
    "        )[2]\n",
    "        pos_j, neg_j = torch.split(all_j, [pos_u.shape[0], neg_u.shape[0]])\n",
    "        loss = self.loss_one_batch(pos_u, pos_i, pos_j, neg_u, neg_i, neg_j)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss\n",
    "\n",
    "    def loss_one_batch(self, pos_u, pos_i, pos_j, neg_u, neg_i, neg_j):\n",
    "        self.computer()\n",
    "        all_user, all_item = self._users, self._items\n",
    "        pos_u_emb0, pos_u_emb = self.embedding_user(pos_u), all_user[pos_u]\n",
    "        pos_i_emb0, pos_i_emb = self.embedding_item(pos_i), all_item[pos_i]\n",
    "        pos_j_emb0, pos_j_emb = self.embedding_item(pos_j), all_item[pos_j]\n",
    "        neg_u_emb0, neg_u_emb = self.embedding_user(neg_u), all_user[neg_u]\n",
    "        neg_i_emb0, neg_i_emb = self.embedding_item(neg_i), all_item[neg_i]\n",
    "        neg_j_emb0, neg_j_emb = self.embedding_item(neg_j), all_item[neg_j]\n",
    "        pos_scores_ui = torch.sum(torch.mul(pos_u_emb, pos_i_emb), dim=-1)\n",
    "        pos_scores_uj = torch.sum(torch.mul(pos_u_emb, pos_j_emb), dim=-1)\n",
    "        neg_scores_ui = torch.sum(torch.mul(neg_u_emb, neg_i_emb), dim=-1)\n",
    "        neg_scores_uj = torch.sum(torch.mul(neg_u_emb, neg_j_emb), dim=-1)\n",
    "        if _beta == 0:\n",
    "            reg_loss = (\n",
    "                    (1 / 2)\n",
    "                    * (\n",
    "                            pos_u_emb0.norm(2).pow(2)\n",
    "                            + pos_i_emb0.norm(2).pow(2)\n",
    "                            + pos_j_emb0.norm(2).pow(2)\n",
    "                    )\n",
    "                    / float(pos_u.shape[0])\n",
    "            )\n",
    "            scores = pos_scores_uj - pos_scores_ui\n",
    "        else:\n",
    "            reg_loss = (\n",
    "                    (1 / 2)\n",
    "                    * (\n",
    "                            pos_u_emb0.norm(2).pow(2)\n",
    "                            + pos_i_emb0.norm(2).pow(2)\n",
    "                            + pos_j_emb0.norm(2).pow(2)\n",
    "                            + neg_u_emb0.norm(2).pow(2)\n",
    "                            + neg_i_emb0.norm(2).pow(2)\n",
    "                            + neg_j_emb0.norm(2).pow(2)\n",
    "                    )\n",
    "                    / float(pos_u.shape[0] + neg_u.shape[0])\n",
    "            )\n",
    "            scores = torch.concat(\n",
    "                [\n",
    "                    pos_scores_uj - pos_scores_ui,\n",
    "                    _beta * (neg_scores_uj - neg_scores_ui),\n",
    "                ],\n",
    "                dim=0,\n",
    "            )\n",
    "        loss = torch.mean(F.softplus(scores))\n",
    "        return loss + _lambda_reg * reg_loss\n"
   ],
   "id": "161a6989f87db746"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "dataset",
   "id": "fad24b8d6542de96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, train_file, valid_file, test_file, device):\n",
    "        self.device = device\n",
    "        # train dataset\n",
    "        train_data = pd.read_table(train_file, header=None, sep=\" \")\n",
    "        train_pos_data = train_data[train_data[2] >= _offset]\n",
    "        train_neg_data = train_data[train_data[2] < _offset]\n",
    "        self.train_data = torch.from_numpy(train_data.values).to(self.device)\n",
    "        self.train_pos_user = torch.from_numpy(train_pos_data[0].values).to(self.device)\n",
    "        self.train_pos_item = torch.from_numpy(train_pos_data[1].values).to(self.device)\n",
    "        self.train_pos_unique_users = torch.unique(self.train_pos_user)\n",
    "        self.train_pos_unique_items = torch.unique(self.train_pos_item)\n",
    "        self.train_neg_user = torch.from_numpy(train_neg_data[0].values).to(self.device)\n",
    "        self.train_neg_item = torch.from_numpy(train_neg_data[1].values).to(self.device)\n",
    "        self.train_neg_unique_users = torch.unique(self.train_neg_user)\n",
    "        self.train_neg_unique_items = torch.unique(self.train_neg_item)\n",
    "        # validation dataset\n",
    "        valid_data = pd.read_table(valid_file, header=None, sep=\" \")\n",
    "        valid_pos_data = valid_data[valid_data[2] >= _offset]\n",
    "        valid_neg_data = valid_data[valid_data[2] < _offset]\n",
    "        self.valid_data = torch.from_numpy(valid_data.values).to(self.device)\n",
    "        self.valid_pos_user = torch.from_numpy(valid_pos_data[0].values).to(self.device)\n",
    "        self.valid_pos_item = torch.from_numpy(valid_pos_data[1].values).to(self.device)\n",
    "        self.valid_pos_unique_users = torch.unique(self.valid_pos_user)\n",
    "        self.valid_pos_unique_items = torch.unique(self.valid_pos_item)\n",
    "        self.valid_neg_user = torch.from_numpy(valid_neg_data[0].values).to(self.device)\n",
    "        self.valid_neg_item = torch.from_numpy(valid_neg_data[1].values).to(self.device)\n",
    "        self.valid_neg_unique_users = torch.unique(self.valid_neg_user)\n",
    "        self.valid_neg_unique_items = torch.unique(self.valid_neg_item)\n",
    "        # test dataset\n",
    "        test_data = pd.read_table(test_file, header=None, sep=\" \")\n",
    "        test_pos_data = test_data[test_data[2] >= _offset]\n",
    "        test_neg_data = test_data[test_data[2] < _offset]\n",
    "        self.test_data = torch.from_numpy(test_data.values).to(self.device)\n",
    "        self.test_pos_user = torch.from_numpy(test_pos_data[0].values).to(self.device)\n",
    "        self.test_pos_item = torch.from_numpy(test_pos_data[1].values).to(self.device)\n",
    "        self.test_pos_unique_users = torch.unique(self.test_pos_user)\n",
    "        self.test_pos_unique_items = torch.unique(self.test_pos_item)\n",
    "        self.test_neg_user = torch.from_numpy(test_neg_data[0].values).to(self.device)\n",
    "        self.test_neg_item = torch.from_numpy(test_neg_data[1].values).to(self.device)\n",
    "        self.test_neg_unique_users = torch.unique(self.test_neg_user)\n",
    "        self.test_neg_unique_items = torch.unique(self.test_neg_item)\n",
    "        self.num_users = (\n",
    "                max(\n",
    "                    [\n",
    "                        self.train_pos_unique_users.max(),\n",
    "                        self.train_neg_unique_users.max(),\n",
    "                        self.valid_pos_unique_users.max(),\n",
    "                        self.valid_neg_unique_users.max(),\n",
    "                        self.test_pos_unique_users.max(),\n",
    "                        self.test_neg_unique_users.max(),\n",
    "                    ]\n",
    "                ).cpu()\n",
    "                + 1\n",
    "        )\n",
    "        self.num_items = (\n",
    "                max(\n",
    "                    [\n",
    "                        self.train_pos_unique_items.max(),\n",
    "                        self.train_neg_unique_items.max(),\n",
    "                        self.valid_pos_unique_items.max(),\n",
    "                        self.valid_neg_unique_items.max(),\n",
    "                        self.test_pos_unique_items.max(),\n",
    "                        self.test_neg_unique_items.max(),\n",
    "                    ]\n",
    "                ).cpu()\n",
    "                + 1\n",
    "        )\n",
    "        self.num_nodes = self.num_users + self.num_items\n",
    "        print(\"users: %d, items: %d.\" % (self.num_users, self.num_items))\n",
    "        print(\n",
    "            \"train: %d pos + %d neg.\"\n",
    "            % (self.train_pos_user.shape[0], self.train_neg_user.shape[0])\n",
    "        )\n",
    "        print(\n",
    "            \"valid: %d pos + %d neg.\"\n",
    "            % (self.valid_pos_user.shape[0], self.valid_neg_user.shape[0])\n",
    "        )\n",
    "        print(\n",
    "            \"test: %d pos + %d neg.\"\n",
    "            % (self.test_pos_user.shape[0], self.test_neg_user.shape[0])\n",
    "        )\n",
    "        #\n",
    "        self._train_neg_list = None\n",
    "        self._train_pos_list = None\n",
    "        self._valid_neg_list = None\n",
    "        self._valid_pos_list = None\n",
    "        self._test_neg_list = None\n",
    "        self._test_pos_list = None\n",
    "        self._A_pos = None\n",
    "        self._A_neg = None\n",
    "        self._degree_pos = None\n",
    "        self._degree_neg = None\n",
    "        self._tildeA = None\n",
    "        self._tildeA_pos = None\n",
    "        self._tildeA_neg = None\n",
    "        self._indices = None\n",
    "        self._paths = None\n",
    "        self._values = None\n",
    "        self._counts = None\n",
    "        self._counts_sum = None\n",
    "        self._L = None\n",
    "        self._L_pos = None\n",
    "        self._L_neg = None\n",
    "        self._L_eigs = None\n",
    "\n",
    "    @property\n",
    "    def train_pos_list(self):\n",
    "        if self._train_pos_list is None:\n",
    "            self._train_pos_list = [\n",
    "                list(self.train_pos_item[self.train_pos_user == u].cpu().numpy())\n",
    "                for u in range(self.num_users)\n",
    "            ]\n",
    "        return self._train_pos_list\n",
    "\n",
    "    @property\n",
    "    def train_neg_list(self):\n",
    "        if self._train_neg_list is None:\n",
    "            self._train_neg_list = [\n",
    "                list(self.train_neg_item[self.train_neg_user == u].cpu().numpy())\n",
    "                for u in range(self.num_users)\n",
    "            ]\n",
    "        return self._train_neg_list\n",
    "\n",
    "    @property\n",
    "    def valid_pos_list(self):\n",
    "        if self._valid_pos_list is None:\n",
    "            self._valid_pos_list = [\n",
    "                list(self.valid_pos_item[self.valid_pos_user == u].cpu().numpy())\n",
    "                for u in self.valid_pos_unique_users\n",
    "            ]\n",
    "        return self._valid_pos_list\n",
    "\n",
    "    @property\n",
    "    def valid_neg_list(self):\n",
    "        if self._valid_neg_list is None:\n",
    "            self._valid_neg_list = [\n",
    "                list(self.valid_neg_item[self.valid_neg_user == u].cpu().numpy())\n",
    "                for u in self.valid_pos_unique_users\n",
    "            ]\n",
    "        return self._valid_neg_list\n",
    "\n",
    "    @property\n",
    "    def test_pos_list(self):\n",
    "        if self._test_pos_list is None:\n",
    "            self._test_pos_list = [\n",
    "                list(self.test_pos_item[self.test_pos_user == u].cpu().numpy())\n",
    "                for u in self.test_pos_unique_users\n",
    "            ]\n",
    "        return self._test_pos_list\n",
    "\n",
    "    @property\n",
    "    def test_neg_list(self):\n",
    "        if self._test_neg_list is None:\n",
    "            self._test_neg_list = [\n",
    "                list(self.test_neg_item[self.test_neg_user == u].cpu().numpy())\n",
    "                for u in self.test_pos_unique_users\n",
    "            ]\n",
    "        return self._test_neg_list\n",
    "\n",
    "    @property\n",
    "    def A_pos(self):\n",
    "        if self._A_pos is None:\n",
    "            self._A_pos = torch.sparse_coo_tensor(\n",
    "                torch.cat(\n",
    "                    [\n",
    "                        torch.stack(\n",
    "                            [self.train_pos_user, self.train_pos_item + self.num_users]\n",
    "                        ),\n",
    "                        torch.stack(\n",
    "                            [self.train_pos_item + self.num_users, self.train_pos_user]\n",
    "                        ),\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                ),\n",
    "                torch.ones(self.train_pos_user.shape[0] * 2).to(_device),\n",
    "                torch.Size([self.num_nodes, self.num_nodes]),\n",
    "            )\n",
    "        return self._A_pos\n",
    "\n",
    "    @property\n",
    "    def degree_pos(self):\n",
    "        if self._degree_pos is None:\n",
    "            self._degree_pos = self.A_pos.sum(dim=1).to_dense()\n",
    "        return self._degree_pos\n",
    "\n",
    "    @property\n",
    "    def tildeA_pos(self):\n",
    "        if self._tildeA_pos is None:\n",
    "            D = self.degree_pos.float()\n",
    "            D[D == 0.0] = 1.0\n",
    "            D1 = torch.sparse_coo_tensor(\n",
    "                torch.arange(self.num_nodes, device=_device)\n",
    "                .unsqueeze(0)\n",
    "                .repeat(2, 1),\n",
    "                D ** (-1 / 2),\n",
    "                torch.Size([self.num_nodes, self.num_nodes]),\n",
    "            )\n",
    "            D2 = torch.sparse_coo_tensor(\n",
    "                torch.arange(self.num_nodes, device=_device)\n",
    "                .unsqueeze(0)\n",
    "                .repeat(2, 1),\n",
    "                D ** (-1 / 2),\n",
    "                torch.Size([self.num_nodes, self.num_nodes]),\n",
    "            )\n",
    "            self._tildeA_pos = torch.sparse.mm(torch.sparse.mm(D1, self.A_pos), D2)\n",
    "        return self._tildeA_pos\n",
    "\n",
    "    @property\n",
    "    def L_pos(self):\n",
    "        if self._L_pos is None:\n",
    "            D = torch.sparse_coo_tensor(\n",
    "                torch.arange(self.num_nodes, device=_device)\n",
    "                .unsqueeze(0)\n",
    "                .repeat(2, 1),\n",
    "                torch.ones(self.num_nodes, device=_device),\n",
    "                torch.Size([self.num_nodes, self.num_nodes]),\n",
    "            )\n",
    "            self._L_pos = D - self.tildeA_pos\n",
    "        return self._L_pos\n",
    "\n",
    "    @property\n",
    "    def A_neg(self):\n",
    "        if self._A_neg is None:\n",
    "            self._A_neg = torch.sparse_coo_tensor(\n",
    "                torch.cat(\n",
    "                    [\n",
    "                        torch.stack(\n",
    "                            [self.train_neg_user, self.train_neg_item + self.num_users]\n",
    "                        ),\n",
    "                        torch.stack(\n",
    "                            [self.train_neg_item + self.num_users, self.train_neg_user]\n",
    "                        ),\n",
    "                    ],\n",
    "                    dim=1,\n",
    "                ),\n",
    "                torch.ones(self.train_neg_user.shape[0] * 2).to(_device),\n",
    "                torch.Size([self.num_nodes, self.num_nodes]),\n",
    "            )\n",
    "        return self._A_neg\n",
    "\n",
    "    @property\n",
    "    def degree_neg(self):\n",
    "        if self._degree_neg is None:\n",
    "            self._degree_neg = self.A_neg.sum(dim=1).to_dense()\n",
    "        return self._degree_neg\n",
    "\n",
    "    @property\n",
    "    def tildeA_neg(self):\n",
    "        if self._tildeA_neg is None:\n",
    "            D = self.degree_neg.float()\n",
    "            D[D == 0.0] = 1.0\n",
    "            D1 = torch.sparse_coo_tensor(\n",
    "                torch.arange(self.num_nodes, device=_device)\n",
    "                .unsqueeze(0)\n",
    "                .repeat(2, 1),\n",
    "                D ** (-1 / 2),\n",
    "                torch.Size([self.num_nodes, self.num_nodes]),\n",
    "            )\n",
    "            D2 = torch.sparse_coo_tensor(\n",
    "                torch.arange(self.num_nodes, device=_device)\n",
    "                .unsqueeze(0)\n",
    "                .repeat(2, 1),\n",
    "                D ** (-1 / 2),\n",
    "                torch.Size([self.num_nodes, self.num_nodes]),\n",
    "            )\n",
    "            self._tildeA_neg = torch.sparse.mm(torch.sparse.mm(D1, self.A_neg), D2)\n",
    "        return self._tildeA_neg\n",
    "\n",
    "    @property\n",
    "    def L_neg(self):\n",
    "        if self._L_neg is None:\n",
    "            D = torch.sparse_coo_tensor(\n",
    "                torch.arange(self.num_nodes, device=_device)\n",
    "                .unsqueeze(0)\n",
    "                .repeat(2, 1),\n",
    "                torch.ones(self.num_nodes, device=_device),\n",
    "                torch.Size([self.num_nodes, self.num_nodes]),\n",
    "            )\n",
    "            self._L_neg = D - self.tildeA_neg\n",
    "        return self._L_neg\n",
    "\n",
    "    @property\n",
    "    def L(self):\n",
    "        if self._L is None:\n",
    "            self._L = (self.L_pos + _alpha * self.L_neg) / (1 + _alpha)\n",
    "        return self._L\n",
    "\n",
    "    @property\n",
    "    def L_eigs(self):\n",
    "        if self._L_eigs is None:\n",
    "            if _eigs_dim == 0:\n",
    "                self._L_eigs = torch.tensor([]).to(_device)\n",
    "            else:\n",
    "                _, self._L_eigs = sp.linalg.eigs(\n",
    "                    sp.csr_matrix(\n",
    "                        (self.L._values().cpu(), self.L._indices().cpu()),\n",
    "                        (self.num_nodes, self.num_nodes),\n",
    "                    ),\n",
    "                    k=_eigs_dim,\n",
    "                    which=\"SR\",\n",
    "                )\n",
    "                self._L_eigs = torch.tensor(self._L_eigs.real).to(_device)\n",
    "                self._L_eigs = F.layer_norm(\n",
    "                    self._L_eigs, normalized_shape=(_eigs_dim,)\n",
    "                )\n",
    "        return self._L_eigs\n",
    "\n",
    "    def sample(self):\n",
    "        if self._indices is None:\n",
    "            self._indices = torch.cat(\n",
    "                [\n",
    "                    torch.stack(\n",
    "                        [self.train_pos_user, self.train_pos_item + self.num_users]\n",
    "                    ),\n",
    "                    torch.stack(\n",
    "                        [self.train_pos_item + self.num_users, self.train_pos_user]\n",
    "                    ),\n",
    "                    torch.stack(\n",
    "                        [self.train_neg_user, self.train_neg_item + self.num_users]\n",
    "                    ),\n",
    "                    torch.stack(\n",
    "                        [self.train_neg_item + self.num_users, self.train_neg_user]\n",
    "                    ),\n",
    "                ],\n",
    "                dim=1,\n",
    "            )\n",
    "            self._paths = (\n",
    "                torch.cat(\n",
    "                    [\n",
    "                        torch.ones(self.train_pos_user.shape).repeat(2),\n",
    "                        torch.zeros(self.train_neg_user.shape).repeat(2),\n",
    "                    ],\n",
    "                    dim=0,\n",
    "                )\n",
    "                .long()\n",
    "                .to(_device)\n",
    "            )\n",
    "            sorted_indices = torch.argsort(self._indices[0, :])\n",
    "            self._indices = self._indices[:, sorted_indices]\n",
    "            self._paths = self._paths[sorted_indices]\n",
    "            self._counts = torch.bincount(self._indices[0], minlength=self.num_nodes)\n",
    "            self._counts_sum = torch.cumsum(self._counts, dim=0)\n",
    "            d = torch.sqrt(self._counts)\n",
    "            d[d == 0.0] = 1.0\n",
    "            d = 1.0 / d\n",
    "            self._values = (\n",
    "                    torch.ones(self._indices.shape[1]).to(_device)\n",
    "                    * d[self._indices[0]]\n",
    "                    * d[self._indices[1]]\n",
    "            )\n",
    "        res_X, res_Y = [], []\n",
    "        record_X = []\n",
    "        (\n",
    "            X,\n",
    "            Y,\n",
    "        ) = (\n",
    "            self._indices,\n",
    "            torch.ones_like(self._paths).long() * 2 + self._paths,\n",
    "        )\n",
    "        loop_indices = torch.zeros_like(Y).bool()\n",
    "        for hop in range(_sample_hop):\n",
    "            loop_indices = loop_indices | (X[0] == X[1])\n",
    "            for i in range(hop % 2, hop, 2):\n",
    "                loop_indices = loop_indices | (record_X[i][1] == X[1])\n",
    "            record_X.append(X)\n",
    "            res_X.append(X[:, ~loop_indices])\n",
    "            res_Y.append(Y[~loop_indices] - 2)\n",
    "            next_indices = (\n",
    "                    self._counts_sum[X[1]]\n",
    "                    - (torch.rand(X.shape[1]).to(_device) * self._counts[X[1]]).long()\n",
    "                    - 1\n",
    "            )\n",
    "            X = torch.stack([X[0], self._indices[1, next_indices]], dim=0)\n",
    "            Y = Y * 2 + self._paths[next_indices]\n",
    "        return res_X, res_Y"
   ],
   "id": "b0f068466dcc942"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "main",
   "id": "de7c4911853f6ac2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def print_test_result():\n",
    "    global best_epoch, test_pre, test_recall, test_ndcg\n",
    "    print(f'Test Result(at {best_epoch:d} epoch):')\n",
    "    for i, k in enumerate(_topks):\n",
    "        print(f'ndcg@{k:d} = {test_ndcg[i]:f}, recall@{k:d} = {test_recall[i]:f}, pre@{k:d} = {test_pre[i]:f}.')\n",
    "\n",
    "\n",
    "def train():\n",
    "    train_loss = model.train_func()\n",
    "    if epoch % _show_loss_interval == 0:\n",
    "        print(f'epoch {epoch:d}, train_loss = {train_loss:f}')\n",
    "\n",
    "\n",
    "def valid(epoch):\n",
    "    global best_valid_ndcg, best_epoch, test_pre, test_recall, test_ndcg\n",
    "    valid_pre, valid_recall, valid_ndcg = model.valid_func()\n",
    "    for i, k in enumerate(_topks):\n",
    "        print(\n",
    "            f'[{epoch:d}/{_epochs:d}] Valid Result: ndcg@{k:d} = {valid_ndcg[i]:f}, recall@{k:d} = {valid_recall[i]:f}, pre@{k:d} = {valid_pre[i]:f}.')\n",
    "    if valid_ndcg[-1] > best_valid_ndcg:\n",
    "        best_valid_ndcg, best_epoch = valid_ndcg[-1], epoch\n",
    "        test_pre, test_recall, test_ndcg = model.test_func()\n",
    "        print_test_result()\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "dataset = MyDataset(_train_file, _valid_file, _test_file, _device)\n",
    "model = Model(dataset).to(_device)\n",
    "\n",
    "best_valid_ndcg, best_epoch = 0., 0\n",
    "test_pre, test_recall, test_ndcg = torch.zeros(len(_topks)), torch.zeros(len(_topks)), torch.zeros(len(_topks))\n",
    "valid(epoch=0)\n",
    "for epoch in range(1, _epochs + 1):\n",
    "    train()\n",
    "    if epoch % _valid_interval == 0:\n",
    "        if not valid(epoch) and epoch - best_epoch >= _stopping_step * _valid_interval:\n",
    "            break\n",
    "print('---------------------------')\n",
    "print_test_result()"
   ],
   "id": "30eaff9be1562472"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
